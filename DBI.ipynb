{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbcumYjuv+qHod9gOMNDot"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import zipfile\n","\n","with zipfile.ZipFile('/content/drive/MyDrive/dog-breed-identification.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/')\n"],"metadata":{"id":"vX7VeArh05mV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n","from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n"],"metadata":{"id":"14OaqqDS2RQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#read the csv file\n","df_labels = pd.read_csv(\"labels.csv\")\n","#store training and testing images folder location\n","train_file = 'train/'\n","test_file = 'test/'"],"metadata":{"id":"-V1HdL7A2VM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check the total number of unique breed in our dataset file\n","print(\"Total number of unique Dog Breeds :\",len(df_labels.breed.unique()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsHs_8Ux2aFo","executionInfo":{"status":"ok","timestamp":1701824600356,"user_tz":-330,"elapsed":3,"user":{"displayName":"sai ram _sai","userId":"08876428510114737633"}},"outputId":"a4b32bca-4050-4a09-d0ec-08184ccf3692"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of unique Dog Breeds : 120\n"]}]},{"cell_type":"code","source":["#specify number\n","num_breeds = 60\n","im_size = 224\n","batch_size = 64\n","encoder = LabelEncoder()"],"metadata":{"id":"5-GZOpCg2i8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get only 60 unique breeds record\n","breed_dict = list(df_labels['breed'].value_counts().keys())\n","new_list = sorted(breed_dict,reverse=True)[:num_breeds*2+1:2]\n","#change the dataset to have only those 60 unique breed records\n","df_labels = df_labels.query('breed in @new_list')"],"metadata":{"id":"zBCxGapk2tRK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create new column which will contain image name with the image extension\n","df_labels['img_file'] = df_labels['id'].apply(lambda x: x + \".jpg\")"],"metadata":{"id":"CDSZfD5F2ydl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = np.zeros((len(df_labels), im_size, im_size, 3), dtype='float32')\n","\n","#iterate over img_file column of our dataset\n","for i, img_id in enumerate(df_labels['img_file']):\n","  #read the image file and convert into numeric format\n","  #resize all images to one dimension i.e. 224x224\n","  #we will get array with the shape of\n","  # (224,224,3) where 3 is the RGB channels layers\n","  img = cv2.resize(cv2.imread(train_file+img_id,cv2.IMREAD_COLOR),((im_size,im_size)))\n","  #scale array into the range of -1 to 1.\n","  #preprocess the array and expand its dimension on the axis 0\n","  img_array = preprocess_input(np.expand_dims(np.array(img[...,::-1].astype(np.float32)).copy(), axis=0))\n","  #update the train_x variable with new element\n","  train_x[i] = img_array"],"metadata":{"id":"VKNQX4hR3BGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y = encoder.fit_transform(df_labels[\"breed\"].values)"],"metadata":{"id":"ncH4AzH33NTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(train_x,train_y,test_size=0.2,random_state=42)"],"metadata":{"id":"hVrGLDn13RYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Image augmentation using ImageDataGenerator class\n","train_datagen = ImageDataGenerator(rotation_range=45,\n","                                   width_shift_range=0.2,\n","                                   height_shift_range=0.2,\n","                                   shear_range=0.2,\n","                                   zoom_range=0.25,\n","                                   horizontal_flip=True,\n","                                   fill_mode='nearest')\n","\n","#generate images for training sets\n","train_generator = train_datagen.flow(x_train,\n","                                     y_train,\n","                                     batch_size=batch_size)\n","\n","#same process for Testing sets also by declaring the instance\n","test_datagen = ImageDataGenerator()\n","\n","test_generator = test_datagen.flow(x_test,\n","                                     y_test,\n","                                     batch_size=batch_size)"],"metadata":{"id":"j_9ZDduo3TEA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#building the model using ResNet50V2 with input shape of our image array\n","#weights for our network will be from of imagenet dataset\n","#we will not include the first Dense layer\n","resnet = ResNet50V2(input_shape = [im_size,im_size,3], weights='imagenet', include_top=False)\n","#freeze all trainable layers and train only top layers\n","for layer in resnet.layers:\n","    layer.trainable = False\n","\n","#add global average pooling layer and Batch Normalization layer\n","x = resnet.output\n","x = BatchNormalization()(x)\n","x = GlobalAveragePooling2D()(x)\n","x = Dropout(0.5)(x)\n","#add fully connected layer\n","x = Dense(1024, activation='relu')(x)\n","x = Dropout(0.5)(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2hu-rmh3ews","executionInfo":{"status":"ok","timestamp":1701824661165,"user_tz":-330,"elapsed":5825,"user":{"displayName":"sai ram _sai","userId":"08876428510114737633"}},"outputId":"afbbc94f-2ae0-4b71-c349-b330c5ac9fa5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94668760/94668760 [==============================] - 3s 0us/step\n"]}]},{"cell_type":"code","source":["#add output layer having the shape equal to number of breeds\n","predictions = Dense(num_breeds, activation='softmax')(x)\n","\n","#create model class with inputs and outputs\n","model = Model(inputs=resnet.input, outputs=predictions)\n","#model.summary()"],"metadata":{"id":"3itDi1TR33V5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#epochs for model training and learning rate for optimizer\n","epochs = 10\n","learning_rate = 1e-3\n","\n","#using RMSprop optimizer to compile or build the model\n","optimizer = RMSprop(learning_rate=learning_rate,rho=0.9)\n","model.compile(optimizer=optimizer,\n","              loss='sparse_categorical_crossentropy',\n","              metrics=[\"accuracy\"])\n","\n","#fit the training generator data and train the model\n","hist = model.fit(train_generator,\n","                 steps_per_epoch= x_train.shape[0] // batch_size,\n","                 epochs= epochs,\n","                 validation_data= test_generator,\n","                 validation_steps= x_test.shape[0] // batch_size)\n","\n","#Save the model for prediction\n","model.save(\"model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"XU-xmOzA39WZ","outputId":"a9b945f1-ed5b-47b5-a909-dd21510c11c8","executionInfo":{"status":"ok","timestamp":1701844630999,"user_tz":-330,"elapsed":10250259,"user":{"displayName":"sai ram _sai","userId":"08876428510114737633"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","64/64 [==============================] - 998s 16s/step - loss: 0.7733 - accuracy: 0.7549 - val_loss: 0.7058 - val_accuracy: 0.7969\n","Epoch 2/10\n","64/64 [==============================] - 994s 16s/step - loss: 0.7339 - accuracy: 0.7763 - val_loss: 0.6868 - val_accuracy: 0.8037\n","Epoch 3/10\n","64/64 [==============================] - 975s 15s/step - loss: 0.7417 - accuracy: 0.7721 - val_loss: 0.6591 - val_accuracy: 0.8037\n","Epoch 4/10\n","64/64 [==============================] - 990s 16s/step - loss: 0.7379 - accuracy: 0.7733 - val_loss: 0.6699 - val_accuracy: 0.8057\n","Epoch 5/10\n","64/64 [==============================] - 996s 16s/step - loss: 0.7452 - accuracy: 0.7684 - val_loss: 0.6961 - val_accuracy: 0.7969\n","Epoch 6/10\n","64/64 [==============================] - 994s 16s/step - loss: 0.7175 - accuracy: 0.7856 - val_loss: 0.6932 - val_accuracy: 0.7998\n","Epoch 7/10\n","64/64 [==============================] - 997s 16s/step - loss: 0.6823 - accuracy: 0.7893 - val_loss: 0.6833 - val_accuracy: 0.8076\n","Epoch 8/10\n","64/64 [==============================] - 995s 16s/step - loss: 0.6850 - accuracy: 0.7942 - val_loss: 0.6920 - val_accuracy: 0.8076\n","Epoch 9/10\n","64/64 [==============================] - 999s 16s/step - loss: 0.6819 - accuracy: 0.7830 - val_loss: 0.7173 - val_accuracy: 0.8105\n","Epoch 10/10\n","64/64 [==============================] - 1009s 16s/step - loss: 0.6796 - accuracy: 0.7956 - val_loss: 0.6995 - val_accuracy: 0.8076\n"]}]},{"cell_type":"code","source":["#load the model\n","model = load_model(\"model\")\n","\n","#get the image of the dog for prediction\n","pred_img_path = 'BullDog.jpeg'\n","#read the image file and convert into numeric format\n","#resize all images to one dimension i.e. 224x224\n","pred_img_array = cv2.resize(cv2.imread(pred_img_path,cv2.IMREAD_COLOR),((im_size,im_size)))\n","#scale array into the range of -1 to 1.\n","#expand the dimension on the axis 0 and normalize the array values\n","pred_img_array = preprocess_input(np.expand_dims(np.array(pred_img_array[...,::-1].astype(np.float32)).copy(), axis=0))\n","\n","#feed the model with the image array for prediction\n","pred_val = model.predict(np.array(pred_img_array,dtype=\"float32\"))\n","\n","#display the image of dog\n","cv2.imshow(\"\", cv2.resize(cv2.imread(pred_img_path, cv2.IMREAD_COLOR), (im_size, im_size)))\n","\n","#display the predicted breed of dog\n","pred_breed = sorted(new_list)[np.argmax(pred_val)]\n","print(\"Predicted Breed for this Dog is :\",pred_breed)"],"metadata":{"id":"SffQTWDlZT_o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701848401008,"user_tz":-330,"elapsed":15922,"user":{"displayName":"sai ram _sai","userId":"08876428510114737633"}},"outputId":"474cc32d-35a6-4902-85ad-27d047396580"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 2s 2s/step\n","Predicted Breed for this Dog is : french_bulldog\n"]}]}]}